The purpose of this section is to explore the reality of what it is like to take new found data science skills into your work place with the challenge of finding practical ways to use your skills, encouraging your coworkers to be better users of data, and develop analytic routines that are individualized to the needs of your organization. Whether you are helping an education institution as a consultant, an administrator leading teachers at a school, or a university department chair, there are things you can do to transform what you've learned in the abstract into more concrete learning objectives in the context of your education work place. We'll discuss this topic using two areas of focus: bringing your organization the gift of speed and scale, and the importance of connecting well with others. We'll close this chapter by discussing some of the ways that K-12 teachers in particular might engage a work culture that is bringing on data science as a problem-solving tool. 

# The Gift of Speed and Scale

The power of doing data a analysis with a programming language like R comes from two improvements over tools like Excel and Google Sheets. These improvements are 1. a massive boost in the speed of your work and 2. a massive boost in the size of the size of the datasets you analyze. Here are some approaches to introducing data science to your education workplace that focus on making the most of these increases in speed and scale. 

### Speed 

Having a routine that allows you to answer analytic questions quickly means that you you'll be tackling a larger volume of analytic questions. 

Imagine an education consultant working with a school district to help them measure the effect of a new intervention on how well their students are learning math. During this process the superintendent presents the idea of comparing quiz scores at the schools in the district. The speed at which the consultant offers some initial answers is important for the purposes of keeping the analytic conversation going. 

When a consultant quickly answers a teacher's analytic question about their students' latest batch of quiz scores, the collaborative analytic process feels more like a fast-paced inspiring conversation with a teammate instead of sluggish correspondence between two people on opposite ends of the country. We've all experienced situations where a question like "Is this batch of quiz scores meaningfully different from the ones my students had six months ago?" took so long to answer that the question itself is unimportant by the time the answer arrives! 

Users of data science techniques in education have wonderful opportunities to contribute in situations like this because speedy answers can be the very thing that sparks more important analytic questions. In our example of the education consultant presented with a superintendent's curiosity about quiz score results, it is not too hard to imagine many other great questions resulting from the initial answers: 

 - How big was the effect of the new intervention, if any? 
 - Do we see similar effects across student subgroups, especially the subgroups we are trying to help the most? 
 - Do we see similar effects across grade levels? 

The trick here is to use statistics, programming, and knowledge about education to raise and answer the right questions quickly so the process feels like a conversation. When there's too much time between analytic questions and their answers, educators lose the momentum required to follow the logical and exploratory path towards understanding the needs of their students. 

*Example: Preparing quiz data to compute average scores* 

```{r}
# TODO: Add an intervention column to make this example feel more connected to the anecdote 
```

Let's take our example of the education consultant tasked with computing the average quiz scores. Imagine the school district uses an online quiz system and each teacher's quiz export looks like this:

```{r}
library(tidyverse)
set.seed(45)

quizzes_1 <- tibble(
    teacher_id = 1, 
    student_id = c(1:3), 
    quiz_1 = sample(c(0:100), 3, replace = TRUE), 
    quiz_2 = sample(c(0:100), 3, replace = TRUE), 
    quiz_3 = sample(c(0:100), 3, replace = TRUE)
)

quizzes_1
```

Tools like Excel and Google Sheets can help you compute statistics like mean scores for each quiz or mean scores for each student fairly quickly, but what if you'd like to do that for five teachers using the exact same method? 
First, let's tidy the data. This will prepare our data nicely to compute any number of summary statistics or plot results. Using `gather` to separate the quiz number and its score for each student will get us a long way: 

```{r}
quizzes_1 %>% 
    gather(quiz_number, score, -c(teacher_id, student_id))
```

This structure makes it easy to compute a number of summary statistics, like getting the mean quiz score for each student: 

```{r}
quizzes_1 %>% 
    gather(quiz_number, score, -c(teacher_id, student_id)) %>% 
    group_by(student_id) %>% 
    summarise(quiz_mean = mean(score))
```

Again, for one dataset this computation is fairly straight forward and can be done with a number of software tools. But what about doing this repeatedly for twenty five teacher quiz exports? Let's look at one way we can do this fairly quickly using R. We'll start by creating two additional datasets as an example: 

```{r}
# Second imaginary dataset
quizzes_2 <- tibble(
    teacher_id = 2, 
    student_id = c(4:6), 
    quiz_1 = sample(c(0:100), 3, replace = TRUE), 
    quiz_2 = sample(c(0:100), 3, replace = TRUE), 
    quiz_3 = sample(c(0:100), 3, replace = TRUE)
)

# Third imaginary dataset
quizzes_3 <- tibble(
    teacher_id = 3, 
    student_id = c(7:9), 
    quiz_1 = sample(c(0:100), 3, replace = TRUE), 
    quiz_2 = sample(c(0:100), 3, replace = TRUE), 
    quiz_3 = sample(c(0:100), 3, replace = TRUE)
)
```

The method we'll use to compute the mean quiz score for each student is to  

1. Use `bind_rows` to combine all three quiz exports into one dataset. Remember, this can be done because each teacher's export uses the same imaginary online quiz system and export feature and thus use the same number of columns and variable names 

1. Paste the code we used in the first example into the script so it cleans and computes the mean on the combined dataset

```{r}
# Use `bind_rows` to combine the three quiz exports 
all_quizzes <- bind_rows(quizzes_1, quizzes_2, quizzes_3) 
```

Note there are now nine rows, one for each student in our dataset of three teacher quiz exports: 

```{r}
all_quizzes
```

Finally, we'll paste the code we used in the first example to prepare the data and compute the mean on the larger dataset: 

```{r}
all_quizzes %>% 
    gather(quiz_number, score, -c(teacher_id, student_id)) %>% 
    group_by(student_id) %>% 
    summarise(quiz_mean = mean(score))
```

The difference in time it takes to do this on three quiz exports using R versus non-programming tools is perhaps not significant. But the speed of computing means across larger volumes of data--say thirty quiz exports--is truly useful to an education consultant looking to help many educators. 

```{r}
# TODO: Develop these ideas more: 
```

Quickly answering analytic questions has a chain effect. It works something like this: Doing things quickly helps people. Helping people builds confidence. Confidence builds innovation. 

Functional programming allows you to apply an analytic procedure on many datasets. 

Speed comes from daily practice. 

Let's look at a few examples 


## Data in Context 

When cleaning and analyzing data is laborious, people tend to generate less data. This can be a problem because less data means less context for the data you do have. Without context, it is difficult to conduct one of the primary cognitive tasks of data analysis: making comparisons. 

For example, imagine a teacher whose students have an average quiz score of 75 percent. This information is helpful to the teacher because it shows her how close she is to some pre-determined average quiz score goal, say 95 percent. But that data alone doesn't tell the teacher how unusual that class average is. For that, you need context. Say that line of code used to compute this teacher's class average quiz score was applied to every classroom and she learned that the school average for the same quiz was 77 percent. From this information the teacher learns that her class average is not very different from everyone else's. This is more information than just the knowledge that her class's average was less than her pre-determined goal of 95 percent. 

## The power of speedy data analysis on creative thinking and questions 

In a brainstorming session, rapid questions and answers tend to lead to free association, which tend to lead to even more interesting questions. When someone on the brainstorm team is fast at doing data analysis, that can help bring answers to questions at a speed that encourages even more questions. On the other hand, the interesting questions that come from rapid question and answer sessions gets interrupted if it takes two weeks to answer one data questions. 

Learn how to scale your colleagues' expectations for the amount of data you can work with. 

Work places that are not used to the speed and scale that programming can bring to datawork need a readjustment of their expectations in just that--speed and scale! Use your empathy skills to imagine the extend of modern data work. Cleaning is done by hand using tools like Excel. Cleaning and statistics techniques are applied to one dataset at a time instead of hundreds at a time. And when a project is complete, the steps needed to complete that project are lost unless they were dutifully documented by the analyst. 

Offer to clean a dataset! Then do it again and do it fast. You are training the expectations of your coworkers by repeatedly demonstrating the scale and speed of the data science techniques that you use. 

# Solving Problems Together 

Data science techniques can be an extremely powerful addition to any educational organizations toolbox for problem-solving. But sometimes being the only person who knows how to code or fit a statistical model makes it easy to forget that the most creative solutions for problems come from a collaborative process that involves a diversity of ideas and viewpoints. Here are some approaches to introducing data science to your education workplace that focus on the collaborative side of problem-solving. 

## Data Science in Education and Empathy 

Adopting data science techniques in an education system that doesn't currently use them takes longer than you think. Your coworkers are used to using data in a certain way. In order to contribute to your system by introducing data science techniques, it is very useful to have a good understanding about where your coworkers are at with asking analytic questions, applying the scientific method, using tools like Excel, and basic statistics like averages. Introducing data science techniques to your system is as much about having good people skills and empathy as it is about learning how to code and fit models. 

## Create a Daily Practice Commitment 

Challenge yourself to use your data science skills every day, even if that means using them in mundane situations. Every minute of practice goes towards your mastery. 

## Build Your Network 

Find allies. These can be folks who are already using data science techniques, folks who are interested in data science techniques, folks who have great analytic thinking skills (even if they don't yet know how to code or fit a regression model). 

## Solve a Problem. Then Over Deliver 

Help out with a project. Then over deliver using your data science skills. 

# For K-12 Teachers 