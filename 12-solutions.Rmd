The purpose of this section is to explore the reality of what it is like to take new found data science skills into your work place with the challenge of finding practical ways to use your skills, encouraging your coworkers to be better users of data, and develop analytic routines that are individualized to the needs of your organization. Whether you are helping an education institution as a consultant, an administrator leading teachers at a school, or a university department chair, there are things you can do to transform what you've learned in the abstract into more concrete learning objectives in the context of your education work place. We'll discuss this topic using two areas of focus: bringing your organization the gift of speed and scale, and the importance of connecting well with others. We'll close this chapter by discussing some of the ways that K-12 teachers in particular might engage a work culture that is bringing on data science as a problem-solving tool. 

When cleaning and analyzing data is laborious, people tend to generate less data. This can be a problem because less data means less context for the data you do have. Without context, it is difficult to conduct one of the primary cognitive tasks of data analysis: making comparisons. 

For example, imagine a teacher whose students have an average quiz score of 75 percent. This information is helpful to the teacher because it shows her how close she is to some pre-determined average quiz score goal, say 95 percent. But that data alone doesn't tell the teacher how unusual that class average is. For that, you need context. Say that line of code used to compute this teacher's class average quiz score was applied to every classroom and she learned that the school average for the same quiz was 77 percent. From this information the teacher learns that her class average is not very different from everyone else's. This is more information than just the knowledge that her class's average was less than her pre-determined goal of 95 percent. 

Learn how to scale your colleagues' expectations for the amount of data you can work with. 

Work places that are not used to the speed and scale that programming can bring to datawork need a readjustment of their expectations in just that--speed and scale! Use your empathy skills to imagine the extend of modern data work. Cleaning is done by hand using tools like Excel. Cleaning and statistics techniques are applied to one dataset at a time instead of hundreds at a time. And when a project is complete, the steps needed to complete that project are lost unless they were dutifully documented by the analyst. 

# The Gift of Speed and Scale

The power of doing data a analysis with a programming language like R comes from two improvements over tools like Excel and Google Sheets. These improvements are 1. a massive boost in the speed of your work and 2. a massive boost in the size of the size of the datasets you analyze. Here are some approaches to introducing data science to your education workplace that focus on making the most of these increases in speed and scale. 

## Working With Data Faster

Having a routine that allows you to answer analytic questions quickly means that you you'll be tackling a larger volume of analytic questions. 

Imagine an education consultant working with a school district to help them measure the effect of a new intervention on how well their students are learning math. During this process the superintendent presents the idea of comparing quiz scores at the schools in the district. The speed at which the consultant offers some initial answers is important for the purposes of keeping the analytic conversation going. 

When a consultant quickly answers a teacher's analytic question about their students' latest batch of quiz scores, the collaborative analytic process feels more like a fast-paced inspiring conversation with a teammate instead of sluggish correspondence between two people on opposite ends of the country. We've all experienced situations where a question like "Is this batch of quiz scores meaningfully different from the ones my students had six months ago?" took so long to answer that the question itself is unimportant by the time the answer arrives! 

Users of data science techniques in education have wonderful opportunities to contribute in situations like this because speedy answers can be the very thing that sparks more important analytic questions. In our example of the education consultant presented with a superintendent's curiosity about quiz score results, it is not too hard to imagine many other great questions resulting from the initial answers: 

 - How big was the effect of the new intervention, if any? 
 - Do we see similar effects across student subgroups, especially the subgroups we are trying to help the most? 
 - Do we see similar effects across grade levels? 

The trick here is to use statistics, programming, and knowledge about education to raise and answer the right questions quickly so the process feels like a conversation. When there's too much time between analytic questions and their answers, educators lose the momentum required to follow the logical and exploratory path towards understanding the needs of their students. 

*Example: Preparing quiz data to compute average scores* 

```{r}
# TODO: Add an intervention column to make this example feel more connected to the anecdote 
```

Let's take our example of the education consultant tasked with computing the average quiz scores. Imagine the school district uses an online quiz system and each teacher's quiz export looks like this:

```{r}
library(tidyverse)
set.seed(45)

quizzes_1 <- tibble(
    teacher_id = 1, 
    student_id = c(1:3), 
    quiz_1 = sample(c(0:100), 3, replace = TRUE), 
    quiz_2 = sample(c(0:100), 3, replace = TRUE), 
    quiz_3 = sample(c(0:100), 3, replace = TRUE)
)

quizzes_1
```

Tools like Excel and Google Sheets can help you compute statistics like mean scores for each quiz or mean scores for each student fairly quickly, but what if you'd like to do that for five teachers using the exact same method? 
First, let's tidy the data. This will prepare our data nicely to compute any number of summary statistics or plot results. Using `gather` to separate the quiz number and its score for each student will get us a long way: 

```{r}
quizzes_1 %>% 
    gather(quiz_number, score, -c(teacher_id, student_id))
```

Note now that in the first version of this dataset, each individual row represented a unique combination of teacher and student. After using `gather`, each row is now a unique combination of teacher, student, and quiz number. This is often talked about as changing a dataset from "wide" to "narrow" because of the change in the width of the dataset. The benefit to this change is that we can compute summary statistics by grouping values in any of the new columns. For example, here is how we would compute the mean quiz score for each student:

```{r}
quizzes_1 %>% 
    gather(quiz_number, score, -c(teacher_id, student_id)) %>% 
    group_by(student_id) %>% 
    summarise(quiz_mean = mean(score))
```

Again, for one dataset this computation is fairly straight forward and can be done with a number of software tools. But what if the education consultant in our example wants to do this repeatedly for twenty five teacher quiz exports? Let's look at one way we can do this fairly quickly using R. We'll start by creating two additional datasets as an example. To make things feel authentic, we'll also add a column to show if the students participated in a new intervention. 

```{r}
# Add intervention column to first dataset 
quizzes_1 <- quizzes_1 %>% 
    mutate(intervention = sample(c(0, 1), 3, replace = TRUE))

# Second imaginary dataset
quizzes_2 <- tibble(
    teacher_id = 2, 
    student_id = c(4:6), 
    quiz_1 = sample(c(0:100), 3, replace = TRUE), 
    quiz_2 = sample(c(0:100), 3, replace = TRUE), 
    quiz_3 = sample(c(0:100), 3, replace = TRUE), 
    intervention = sample(c(0, 1), 3, replace = TRUE)
)

# Third imaginary dataset
quizzes_3 <- tibble(
    teacher_id = 3, 
    student_id = c(7:9), 
    quiz_1 = sample(c(0:100), 3, replace = TRUE), 
    quiz_2 = sample(c(0:100), 3, replace = TRUE), 
    quiz_3 = sample(c(0:100), 3, replace = TRUE), 
    intervention = sample(c(0, 1), 3, replace = TRUE)
)
```

The method we'll use to compute the mean quiz score for each student is to: 

1. Combine all the datasets into one big dataset: Use `bind_rows` to combine all three quiz exports into one dataset. Remember, this can be done because each teacher's export uses the same imaginary online quiz system and export feature and thus use the same number of columns and variable names 

1. Reuse the code from the first dataset on the new bigger dataset: Paste the code we used in the first example into the script so it cleans and computes the mean on the combined dataset 

1. Compute the mean of each student: Now that the data is arranged so that each row is a unique combination of teacher, student, quiz number, and intervention status, we can compute the mean quiz score for each student. 

```{r}
# Use `bind_rows` to combine the three quiz exports into one big dataset
all_quizzes <- bind_rows(quizzes_1, quizzes_2, quizzes_3) 
```

Note there are now nine rows, one for each student in our dataset of three teacher quiz exports: 

```{r}
all_quizzes
```

We'll combine the cleaning and computation of the mean steps neatly into one this chunk of code:

```{r}
# Reuse the code from the first dataset on the new bigger dataset
all_quizzes %>% 
    gather(quiz_number, score, -c(teacher_id, student_id, intervention)) %>% 
    # Compute the mean of each student
    group_by(student_id, intervention ) %>% 
    summarise(quiz_mean = mean(score))
```

Note here that our imaginary education consultant from the example is thinking ahead by including the `intervention` column. By doing so she's opened the possibility of collaboratively exploring any possible differences in the scores between the students who had the intervention and the students who did not when she reviews and discusses these results with the school staff. Adding these types of details ahead of time is one way to build conversation starters into your collaborations. It is also a way to get faster at responding to curiosities by anticipating useful questions from your clients. 

The difference in time it takes to do this on three quiz exports using R versus non-programming tools is perhaps not significant. But the speed of computing means across larger volumes of data--say thirty quiz exports--is truly useful to an education consultant looking to help many educators. 

*Summary* 

While getting fast at answering analytic questions is not a silver bullet (but really, what is?), it does have a chain effect often leads to creative solutions. It works something like this: 

 1. Answering analytic questions faster helps more people
 1. Helping more people creates opportunities for more data science practice 
 1. Helping more people also helps educate those same people about the solutions data science tools can offer 
 1. Lots of practice combined with a common understanding of the value of data science tools in the education workplace nurtures confidence 
 1. Confidence leads to the courage required to experiment with interesting solutions for designing the best solutions for students 

Here are more ways to get faster at answering analytic questions: 

 - Recognize when you are using similar chunks of code to do repetitive operations. Store that code in an accessible place and reuse it 
 - Keep a notebook of the questions teachers and administrators ask to help you develop an instinct for common patterns of questions. Write your code to anticipate these questions 
 - Learn to use functions and packages like `purrr` to work on many datasets at once 
 - Install a prototyping habit by getting comfortable with quickly producing rough first drafts of your analysis. Your audience can give valuable feedback early and feel like you are quickly on the path to developing useful answers to their questions

## Working With More Data

Improving outcomes in education is about learning, obviously for the students, but just as importantly for the people teaching the students. The more data is available to examine, the more school staff learn about what is working for their students. Using R to prepare and analyze data so it is repeatable and easy to share increases the amount of data you can work with on an order of magnitude compared to tools like Google Sheets. 

Working with data past a certain size, say 10,000 rows, is difficult because you have to interact with each row through the graphical user interface. Instead, you can work with larger datasets like using programming languages like R to issue complex instructions for acting on the data rather than using a mouse and keyboard to act on what you can see on the screen. 

*Example: Replacing Many Student Names With Numerical IDs*

Say, for example, an elementary school administrator wants to replace each student name in a classroom dataset with a unique numerical ID. Doing this in a spreadsheet using good old fashioned data entry is fairly straightforward. Doing this for a whole school's worth of classrooms though, demands a different approach. Rather than hand enter a unique id into a spreadsheet, the administrator can write an R script that executes the following steps: 

 1. Use `read_csv` to store every classroom's student list into the computer's memory
 1. Use `bind_rows` to combine the separate lists into one long list 
 1. Use `mutate` to replace student names with a randomized and unique numerical ID 
 1. Use `split` to separate the data into classrooms again 
 1. Use `purrr` and `write_csv` to create and rename individual spreadsheets to send back to teachers 
 
With some initial investment into thoughtful coding on the front end of this problem, the admininistrator now has a script she can use repeatedly in the future when she needs to do this task again.

```{r}
# TODO: More examples of differences in scale 
```

*Other Ways to Reimagine the Scale of Your Work* 

**REFLECT ON YOUR CURRENT SCALE. THEN PUSH TO THE NEXT LEVEL**: 

**LOOK FOR LOTS OF SIMILARLY STRUCTURED DATA**: Train your eyes to be alert to repositories that contain many datasets that have the exact same structure, then design ways to act on all those datasets at once. Data systems in education generate standardized data tables all the time. It's one of the side effects of automation. Software developers design data systems to automatically generate many datasets for many people. The result is many datasets that contain different data, but all have the same number of columns and the same column names. This uniformity creates the perfect condition for R scripts to automatically act on these datasets in a way that is predictable and repeatable. Imagine a student information system that exports a list of students, their teacher, their grade level, and the number of school days attended to date. School administrator's that have a weekly routine of exporting this data and storing it in a folder on their laptop will generate many uniformly structured datasets. When you train your eyes to see this as an opportunity to act on a lot of data at once, you will find an abundance of chances to transform data on a large scale so school staff can freely explore and ask questions aimed at improving the student experience. 

**CLEANING DATA**: Folks who work in education want to look at data about their students with tools like Excel, but the data is frequently not ready for analysis. You can empower these folks to explore data and ask more questions by being alert to opportunities to prepare lots of data for analysis. Offer to clean a dataset! Then do it again and do it fast. When you get into this habit, you not only train your data cleaning skills but you also train your education client's expectations for how quickly you can prepare data for them. 

# Solving Problems Together 

Data science techniques can be an extremely powerful addition to any educational organizations toolbox for problem-solving. But sometimes being the only person who knows how to code or fit a statistical model makes it easy to forget that the most creative solutions for problems come from a collaborative process that involves a diversity of ideas and viewpoints. Here are some approaches to introducing data science to your education workplace that focus on the collaborative side of problem-solving. 

## Data Science in Education and Empathy 

Adopting data science techniques in an education system that doesn't currently use them takes longer than you think. Your coworkers are used to using data in a certain way. In order to contribute to your system by introducing data science techniques, it is very useful to have a good understanding about where your coworkers are at with asking analytic questions, applying the scientific method, using tools like Excel, and basic statistics like averages. Introducing data science techniques to your system is as much about having good people skills and empathy as it is about learning how to code and fit models. 

## Create a Daily Practice Commitment 

Challenge yourself to use your data science skills every day, even if that means using them in mundane situations. Every minute of practice goes towards your mastery. 

## Build Your Network 

Find allies. These can be folks who are already using data science techniques, folks who are interested in data science techniques, folks who have great analytic thinking skills (even if they don't yet know how to code or fit a regression model). 

## Solve a Problem. Then Over Deliver 

Help out with a project. Then over deliver using your data science skills. 

# For K-12 Teachers 