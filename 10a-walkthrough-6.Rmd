---
title: "Chapter 11 Walkthrough: Longitudinal Analysis"
author: 
date: 
output: html_document
---

# Vocabulary 

Read in
Aggregate data 
Vector 
List

# 11.1 Introduction 

The authors chose to use a publicly available dataset for this walkthrough. Like most publicly available datasets, this one contains aggregate data. 

# 11.2 Special Education Child Count and Environment Data

You can download these datasets on the United States Department of Education website: [https://www2.ed.gov/programs/osepidea/618-data/state-level-data-files/index.html#bccee]("https://www2.ed.gov/programs/osepidea/618-data/state-level-data-files/index.html#bccee").

# 11.2.1 Reading In One Dataset 

When you are designing an analysis that uses multiple datasets that all have the same structure, you can read in each dataset using one chunk of code. This chunk of code will store each dataset as an element of a list. 

Before doing that, you can explore just one of the datasets briefly to see what you can learn about the dataset's structure. Clues from this initial exploration of one dataset informs how you read in all the datasets at once later on. For example, this first dataset has some lines at the top that don't actually contain data: 

```{r}
library(tidyverse)

read_csv("10a-walkthrough-6-data/bchildcountandedenvironments2012.csv")
```

The rows containing "Extraction Date:", "Updated:" and "Revised:" aren't actually rows. They're notes the authors left at the top of the dataset to show when the dataset was changed. 

`read_csv` uses the first row as the variable names unless told otherwise, so we need to explicitly tell `read_csv` to skip those lines using the `skip` argument. If we don't, `read_csv` assumes the very first line--the one that says "Extraction Date:"--is the correct row of variable names. That's why calling `read_csv` without the `skip` argument results in a bunch of column names like `X4`. When there's no obvious column name to read in, `read_csv` names them `X[...]` and let's you know in a warning message. 

Try using `skip = 4` in your call to `read_csv`:

```{r}
read_csv("10a-walkthrough-6-data/bchildcountandedenvironments2012.csv", skip = 4)
```

The `skip` argument told `read_csv` to think of the line containing "Year", "State Name", and so on as the first line. That's why using `skip = 4` gave you a dataset with "Year", "State Name", and so on as variable names. 

# 11.2.1 Reading In Many Datasets 

Will the `read_csv` and `skip = 4` combination work on all our datasets? To find out, we'll use this strategy: 

 - Store a vector of filenames and paths in a list. These paths point to our datasets
 - Pass the list of filenames as arguments to `read_csv` using `purrr::map`, including `skip = 4` in our `read_csv` call
 - Examine the new list of datasets to see if the variable names are correct in each

Imagine a widget-making machine that works by acting on raw materials it receives on a conveyer belt. This widget-making machine follows one set of instructions on each of the raw materials it receives. You are the operator of the machine and you design instructions to get a widget out of the raw materials. Your plan might look something like this: 

 - *Raw materials*: a list of filenames and their paths 
 - *Widget-making machine*: `purrr:map()`
 - *Widget-making instructions*: `read_csv(path, skip = 4) 
 - *Expected widgets*: a list of datasets

Let's create the raw materials first. Use `list.files` to make a list of filenames and their paths and name that list `filenames`: 

```{r}
# Get filenames from the data folder 
filenames <- list.files("10a-walkthrough-6-data", full.names = TRUE)

# A list of filenames and paths
filenames
```

That made a list of six filenames, one for each year of child count data stored in the data folder. Now pass our raw materials, the list called `filenames`, to our widget-making machine called `map` and give the machine the instructions `read_csv(., skip = 4)`. Name the list of widgets it cranks out `all_files`:

```{r}
# Pass filenames to map and read_csv
all_files <- filenames %>% map(., ~read_csv(., skip = 4))

# A list of datasets
all_files
```

It is important here to think ahead. Ultimately we want to combine all the datasets in `all_files` into one dataset using `bind_rows`. But that will only work if all the datasets in our list have the same number of columns and the same column names. We can check our column names by using `map` and `names`: 

```{r}
all_files %>% map(names)
```

And we can check the number of columns by using `map` and `ncol`:

```{r}
all_files %>% map(ncol)
```

If this is your first time working on education data, congratulations on finding an extremely common problem! By now you've not only noticed that the number of columns don't match across datasets, but the column names don't match either. This is a problem because we won't be able to combine the datasets into one long one. When we try, `bind_rows` returns a dataets with 100 columns instead of the expected 50. 

```{r}
bind_rows(all_files)
```

# 11.2.2 Cleaning the Dataset 

1. Fix the variable names in the 2016 data 
2. Select the gender-related variables 
3. Rename the variables 
4. Combine the datasets 
5. Tidy the dataset

## Fix the variable names in the 2016 data

```{r}
filenames
```

Once know the 2016 dataset is stored in the fifth element of our list, we can pluck it out by using double brackets: 

```{r}
all_files[[5]]
```

```{r}
all_files[[5]] <- read_csv(filenames[[5]], skip = 3)
```

## Select the gender-related variables 

```{r}
all_files[[1]] %>% 
    select_at(vars(Year, contains("State", ignore.case = FALSE), contains("male"))) 
```

# 11.3 How have Child Counts Changed Over Time? 

# 11.3.1 Transform the Dataset 

# 11.3.2 Visualize the Dataset  

# 11.3.3 Model the Dataset 

# 11.4 Ask More Questions  

# 11.5 Aggregate Data as Context for Student Data 