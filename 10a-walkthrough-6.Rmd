---
title: "Chapter 11 Walkthrough: Longitudinal Analysis"
author: 
date: 
output: html_document
---

# Vocabulary 

Read in
Aggregate data 
Vector 
List
Tidy format
`select_at`
`mutate`

# 11.1 Introduction 

The authors chose to use a publicly available dataset for this walkthrough. Like most publicly available datasets, this one contains aggregate data. 

# 11.2 Special Education Child Count and Environment Data

You can download these datasets on the United States Department of Education website: [https://www2.ed.gov/programs/osepidea/618-data/state-level-data-files/index.html#bccee]("https://www2.ed.gov/programs/osepidea/618-data/state-level-data-files/index.html#bccee").

# 11.2.1 Reading In One Dataset 

When you are designing an analysis that uses multiple datasets that all have the same structure, you can read in each dataset using one chunk of code. This chunk of code will store each dataset as an element of a list. 

Before doing that, you can explore just one of the datasets briefly to see what you can learn about the dataset's structure. Clues from this initial exploration of one dataset informs how you read in all the datasets at once later on. For example, this first dataset has some lines at the top that don't actually contain data: 

```{r}
library(tidyverse)

read_csv("10a-walkthrough-6-data/bchildcountandedenvironments2012.csv")
```

The rows containing "Extraction Date:", "Updated:" and "Revised:" aren't actually rows. They're notes the authors left at the top of the dataset to show when the dataset was changed. 

`read_csv` uses the first row as the variable names unless told otherwise, so we need to explicitly tell `read_csv` to skip those lines using the `skip` argument. If we don't, `read_csv` assumes the very first line--the one that says "Extraction Date:"--is the correct row of variable names. That's why calling `read_csv` without the `skip` argument results in a bunch of column names like `X4`. When there's no obvious column name to read in, `read_csv` names them `X[...]` and let's you know in a warning message. 

Try using `skip = 4` in your call to `read_csv`:

```{r}
read_csv("10a-walkthrough-6-data/bchildcountandedenvironments2012.csv", skip = 4)
```

The `skip` argument told `read_csv` to think of the line containing "Year", "State Name", and so on as the first line. That's why using `skip = 4` gave you a dataset with "Year", "State Name", and so on as variable names. 

# 11.2.1 Reading In Many Datasets 

Will the `read_csv` and `skip = 4` combination work on all our datasets? To find out, we'll use this strategy: 

 - Store a vector of filenames and paths in a list. These paths point to our datasets
 - Pass the list of filenames as arguments to `read_csv` using `purrr::map`, including `skip = 4` in our `read_csv` call
 - Examine the new list of datasets to see if the variable names are correct in each

Imagine a widget-making machine that works by acting on raw materials it receives on a conveyer belt. This widget-making machine follows one set of instructions on each of the raw materials it receives. You are the operator of the machine and you design instructions to get a widget out of the raw materials. Your plan might look something like this: 

 - *Raw materials*: a list of filenames and their paths 
 - *Widget-making machine*: `purrr:map()`
 - *Widget-making instructions*: `read_csv(path, skip = 4) 
 - *Expected widgets*: a list of datasets

Let's create the raw materials first. Use `list.files` to make a list of filenames and their paths and name that list `filenames`: 

```{r}
# Get filenames from the data folder 
filenames <- list.files("10a-walkthrough-6-data", full.names = TRUE)

# A list of filenames and paths
filenames
```

That made a list of six filenames, one for each year of child count data stored in the data folder. Now pass our raw materials, the list called `filenames`, to our widget-making machine called `map` and give the machine the instructions `read_csv(., skip = 4)`. Name the list of widgets it cranks out `all_files`:

```{r}
# Pass filenames to map and read_csv
all_files <- filenames %>% map(., ~read_csv(., skip = 4))

# A list of datasets
all_files
```

It is important here to think ahead. Ultimately we want to combine all the datasets in `all_files` into one dataset using `bind_rows`. But that will only work if all the datasets in our list have the same number of columns and the same column names. We can check our column names by using `map` and `names`: 

```{r}
all_files %>% map(names)
```

And we can check the number of columns by using `map` and `ncol`:

```{r}
all_files %>% map(ncol)
```

If this is your first time working on education data, congratulations on finding an extremely common problem! By now you've not only noticed that the number of columns don't match across datasets, but the column names don't match either. This is a problem because we won't be able to combine the datasets into one long one. When we try, `bind_rows` returns a dataets with 100 columns instead of the expected 50. 

```{r}
bind_rows(all_files)
```

We'll correct this in the next section by selecting and renaming our variables, but it's good to notice this problem early in the process so you know to work on it later. 

# 11.2.2 Cleaning the Dataset 

Transforming your dataset before visualizing it and fitting models is critical. It's easier to write code when variable names are concise and informative. Many functions in R, especially those in the `ggplot2` package, work best when datsets are in a "tidy" format. It's easier to do an analysis when you have only the information you need and very little extraneous data that can confuse your thought process. 

Since we're demonstrating one example of a cleaning process, we've worked through the whole thing and can preview the steps we took: 

1. Fix the variable names in the 2016 data 
4. Combine the datasets 
2. Pick variables 
1. Filter for the desired categories
3. Rename the variables 
3. Standardized the state names
5. Gather columns
3. Convert classes
3. Explore NAs

But in real life, data scientists often don't know the steps they'll need to take to prepare a dataset until they dive into the work. Learning what data transformations are needed requires exploration, trial and error, and clarity on the analytic questions you want to answer. 

After a lot of exploring, these are the steps we settled on for this particular analysis.  When you do your own, you will find all sorts of different things to transform. As you do more and more data analysis, your instincts for what to transform will also improve. 

## Fix the variable names in the 2016 data

When we print the 2016 dataset, we notice that the variable names are an actual year and an actual state name. Instead, we want them to be the actual variable names `Year` and `State Name`. To see that, we need to find which list element contains the 2016 data. The order of the list elements was set all the way back when we fed `map` our list of filenames. If we look at `filenames` again, we see that the 2016 dataset was stored in the fifth element: 

```{r}
filenames
```

Once know the 2016 dataset is stored in the fifth element of our list, we can pluck it out by using double brackets: 

```{r}
all_files[[5]]
```

We used `skip = 4` when we read in those datasets. That worked for all datasets except the fifth one. In that one, skipping four lines left out the variable name row. To fix it, we'll read the 2016 dataset again using the `read_csv` and the fifth element of `filenames`. We'll assign the newly read dataset to the fifth element of the `all_files` list: 

```{r}
all_files[[5]] <- read_csv(filenames[[5]], skip = 3)
```

Try printing `all_files` now. You can confirm we fixed the problem by verifying that all variable names are correct. 

## Select variables 

Now that we know all our datasets have variable names, we can start simplifying our datasets by picking the variables. This is a good place to think carefully about which variables we pick. This usually requires a fair amount of trial and error, but here is what we found we needed: 

 - Our analytic questions are about gender so let's pick the gender variables 
 - Later, we'll need to filter our dataset by disability category and program location so we'll want `SEA Education Environment` and `SEA Disability Category`
 - We want to make comparisons by state and reporting year so we'll also pick `State Name` and `Year`

Combining `select_at` and `contains` is a convenient way to pick these variables without writing a lot of code. Knowing that we want variables that contain the acronym "SEA" and variables that contain "male" in their names, we can pass those characters to `contains`:

```{r}
all_files[[1]] %>% 
    select_at(vars(Year, contains("State", ignore.case = FALSE), contains("SEA", ignore.case = FALSE), contains("male"))) 
```

That code chunk verifies that we got the variables we want, so now we will turn the code chunk into a function called `pick_vars`. We will then use `map` to feed our list of datasets, `all_files`, to the function. This will result in a newly transformed `all_files` list that contains six datasets, all with the desired variables. 

```{r}
pick_vars <- function(df) {
    df %>% 
        select_at(vars(Year, contains("State", ignore.case = FALSE), contains("SEA", ignore.case = FALSE), contains("male"))) 
}

all_files <- all_files %>% 
    map(pick_vars)
```

## Combine six datasets in a list into one dataset 

Now we'll turn our attention to combining the datasets in our list `all_files` into one dataset. We'll use `bind_rows`, which combines datasets by adding each one to the bottom of the one before it. The first step is to check and see if our datasets have the same number of variables and the same variable names. When we use `names` on our list of newly changed datasets, we see that each dataset's variable names are the same: 

```{r}
all_files %>% map(names)
```

That means that we can combine all six datasets into one using `bind_rows`. We'll call this newly combined dataset `child_counts`:

```{r}
child_counts <-  all_files %>% 
    bind_rows()
```

Since we know that a) each of our six datasets had eight variables and b) our combined dataset also has eight variables, we can conclude that all our rows combined together correctly. But let's use `str` to verify: 

```{r}
str(child_counts)
```

## Filter for the desired disabilities and age groups

We want to explore gender related variables, but our dataset has additional aggregate data for other subgroups. For example, we can use `count` to explore all the different disability groups in the dataset: 

```{r}
child_counts %>% 
    count(`SEA Disability Category`)
```

Since we will be visualizing and modeling gender variables for all students in the dataset, we'll filter out all subgoups except "All Disabilities" and the age totals: 

```{r}
child_counts <- child_counts %>% 
    filter(`SEA Disability Category` == "All Disabilities", 
           `SEA Education Environment` %in% c("Total, Age 3-5", "Total, Age 6-21")) 
```

## Rename the variables

In the next section we'll be preparing the dataset for visualization and modeling by "tidying" it. When we write code to transform datasets, we have to repeatedly type the column names so it's useful to change them to ones with reasonable lengths and without spaces. 

```{r}
child_counts <- child_counts %>% 
    rename(year = Year,
           state = "State Name", 
           age = "SEA Education Environment",
           disability = "SEA Disability Category", 
           f_3_5 = "Female Age 3 to 5", 
           m_3_5 = "Male Age 3 to 5", 
           f_6_21 = "Female Age 6 to 21", 
           m_6_21 = "Male Age 6 to 21")
```

## Clean state names

You might have noticed that some state names in our dataset are in upper case letters and some are in lower case letters: 

```{r}
child_counts %>% 
    count(state) %>% head()
```

If we leave it like this, R will treat the upper case states and lower case states of the same name as different states. We can use `mutate` and `tolower` to transform all the state names to lowercase letters. 

```{r}
child_counts <- child_counts %>% 
    mutate(state = tolower(state)) 
```

## Tidy the dataset 

Visualizing and modeling our data will be much easier if our dataset is in a "tidy" format. In his paper *Tidy Data*, Hadley Wickham defines tidy datasets where

>1. Each variable forms a column.
>2. Each observation forms a row.
>3. Each type of observational unit forms a table.

The gender variables in our dataset are spread across four columns, one representing a combination of gender and age range. We can use `gather` to bring the gender variable into one column. In this transformation, we create two new columns: a `gender` column and a `total` column. The `total` column will contain the number of students in each row's gender and age category.  

```{r}
child_counts <- child_counts %>% 
    gather(gender, total, f_3_5:m_6_21)
```

To make the values of the `gender` column more intuitive, we'll use `case_when` to transform the values to either "f" or "m":

```{r}
child_counts <- child_counts %>% 
    mutate(gender = case_when(
        gender == "f_3_5" ~ "f", 
        gender == "m_3_5" ~ "m", 
        gender == "f_6_21" ~ "f", 
        gender == "m_6_21" ~ "m", 
        TRUE ~ as.character(gender)
    ))
```

## Convert classes

The values in the `total` column represent the number of students from a specific year, state, gender, and age group. We know from the `chr` under their variable names that R is treating these values like characters instead of numbers. While R does a decent job of treating numbers like numbers when needed, it's much safer to prepare the dataset by changing these character columns to number columns. We'll use `dplyr::mutate_at` to conveniently change the count columns. 

```{r convert to numeric}
child_counts <- child_counts %>% 
    mutate(total = as.numeric(total)) 
child_counts
```

Changing these count columns from character classes to number classes resulted in two changes. First, the `chr` under these variable names has no changed to `dbl`, short for "double-precision". This lets us know that R recognizes these values as numbers with decimal points. Second, the blank values changed to `NA`. When R sees a character class value like `"4"`, it knows to change it to numeric class `4`. But there is no obvious number represented by a character class like `""`, so it changes it to `NA`: 

```{r}
# Convert a character to a number 
as.numeric("4")

# Convert a blank character to number
as.numeric("")
```

Similarly, the variable `year` needs to be changed from the character format to the date format. Doing so will make sure R treats this variable like a point in time when we plot our dataset. The package `lubridate` has a handy function called `ymd` that can help us. We just have to use the `truncated` argument to let R know we don't have a month and date to convert. 

```{r convert date}
library(lubridate)

child_counts <- child_counts %>% 
    mutate(year = ymd(year, truncated = 2))
```

## Explore and address NAs

You'll notice that some rows in the `total` column contain an `NA`. When we used `gather` to create a `gender` column, R created unique rows for every year, state, age, disability, and gender combination. Since the original dataset had both gender and age range store in a column like `Female Age 3 to 5`, R made rows that contained new no `total` value. For example, there is no student count for the `age` value "Total, Age 3-5" that also has the `gender` value for female students who were age 6-21. You can see that more clearly by sorting the dataset by year, state, and gender:

```{r}
child_counts %>% 
    arrange(year, state, gender)
```

We can simplify our dataset by removing these rows, leaving us with one row for each for 

 - females age 3-5
 - females age 6-21
 - males age 3-5 
 - males age 6-21 

... asscoiated with a state and reporting year: 

```{r remove NAs}
child_counts <- child_counts %>% 
    filter(!is.na(total)) 
```

We can verify that we have the four rows we want per year and state when we do our sort again: 

```{r verify rows}
child_counts %>% 
    arrange(year, state, gender)
```

# 11.3 How have Child Counts Changed Over Time? 

# 11.3.2 Visualize the Dataset  

```{r filter most populated}
high_pop <- child_counts %>% 
    filter(state %in% c("california", "texas", "new york", "florida", "illinois"))
```

```{r total female students over time}
high_pop %>% 
    filter(gender == "f", age == "Total, Age 6-21") %>%
    ggplot(aes(x = year, y = total, color = state)) + 
    geom_freqpoly(stat = "identity")
```

```{r total students over time }
high_pop %>% 
    group_by(year, state) %>% 
    summarise(n = sum(total)) %>% 
    ggplot(aes(x = year, y = n, color = state)) + 
    geom_freqpoly(stat = "identity")
```

```{r median total per state}
high_pop %>% 
    group_by(year, state) %>% 
    summarise(n = sum(total)) %>% 
    ggplot(aes(x = state, y = n)) + 
    geom_boxplot()
```

```{r male to female ratio over time }
high_pop %>% 
    filter(age == "Total, Age 6-21") %>% 
    spread(gender, total) %>% 
    mutate(ratio = m / f) %>%
    ggplot(aes(x = year, y = ratio, color = state)) + 
    geom_freqpoly(stat = "identity") + 
    labs(title = "Male student to female student ratio over time", 
         subtitle = "Ages 6-21")
```

```{r plot female students to male students}

```

# 11.3.3 Model the Dataset 

Model differences in identification by gender: 

```{r make model data}
model_data <- child_counts %>% 
    filter(age == "Total, Age 6-21") %>% 
    mutate(year = as.factor(year(year))) %>% 
    spread(gender, total) %>% 
    # Compute male student to female student ratio 
    mutate(ratio = m / f) %>% 
    select(-c(age, disability))
```

```{r check factor sample sizes}
model_data %>% count(year)
```

```{r fit model for year predicting ratio }
ratio_year <- lm(ratio ~ year, data = model_data)
summary(ratio_year)
```

# 11.4 Ask More Questions  

# 11.5 Aggregate Data as Context for Student Data 